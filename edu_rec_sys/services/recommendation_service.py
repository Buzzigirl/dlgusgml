# edu_rec_sys/services/recommendation_service.py

import os
import pickle
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import ast
from collections import defaultdict
import requests
from django.conf import settings

# âš ï¸ Pandas Warning Suppression (User Request)
pd.options.mode.chained_assignment = None


# 1ë‹¨ê³„ì—ì„œ ë§Œë“  ëª¨ë¸ íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
from ..ml_models.transformer import (
    SharedEmbeddings, TermRecTransformer, Collator,
    build_samples_full_history, safe_int0, safe_float0
)

def filter_last_per_student(samples):
    """í•™ìƒë³„ë¡œ ê°€ì¥ ë§ˆì§€ë§‰ í•™ê¸° ìƒ˜í”Œë§Œ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜"""
    last = {}
    for s in samples:
        sid = s['student_id']
        if sid not in last or s['target_term'] > last[sid]['target_term']:
            last[sid] = s
    return list(last.values())

# --- ğŸ’¡ ì¤‘ìš”: Singleton íŒ¨í„´ ---
# RecommendationService ê°ì²´ë¥¼ ë‹¨ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì—¬ ë©”ëª¨ë¦¬ì— ìœ ì§€í•©ë‹ˆë‹¤.
class RecommendationService:
    _instance = None

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            cls._instance = super(RecommendationService, cls).__new__(cls, *args, **kwargs)
        return cls._instance

    def __init__(self):
        # ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë©´ ë‹¤ì‹œ ì‹¤í–‰í•˜ì§€ ì•Šë„ë¡ ë°©ì§€
        if hasattr(self, 'initialized'):
            return
        
        print("ğŸš€ RecommendationService ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")

        # --- 1. ê²½ë¡œ ì„¤ì • ---
        self.DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.DATA_DIR = os.path.join(settings.BASE_DIR, 'edu_rec_sys', 'data')
        # ëª¨ë¸ ë° ì„ë² ë”© íŒŒì¼ ê²½ë¡œ
        self.MODEL_DIR = os.path.join(settings.BASE_DIR, 'sub')
        self.EMBEDDING_DIR = os.path.join(settings.BASE_DIR, 'sub')
        self.RAW_DATA_DIR = os.path.join(settings.BASE_DIR, 'edu_rec_sys', 'data')

        # --- 1.5 Checking and Downloading Files ---
        self._check_and_download_files()

        # --- 2. ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë“œ ---
        self._load_preprocessed_data()
        
        # --- 3. ëª¨ë¸ì— í•„ìš”í•œ íŒŒë¼ë¯¸í„° ê³„ì‚° ---
        self._calculate_model_params()
        
        # --- 4. ëª¨ë¸ êµ¬ì¡° ì •ì˜ ë° ê°€ì¤‘ì¹˜ ë¡œë“œ ---
        self._load_model()
        
        # --- 5. ì¶”ì²œì— í•„ìš”í•œ ë§µ(map) ë° ë°ì´í„° ì¤€ë¹„ ---
        self._prepare_prediction_assets()

        self.initialized = True
        self.initialized = True
        print("âœ… RecommendationService ì´ˆê¸°í™” ì™„ë£Œ.")
        print("\n" + "="*50)
        print("âœ¨âœ¨âœ¨ ëª¨ë“  ì‹œìŠ¤í…œ ê°€ë™ ì¤€ë¹„ ì™„ë£Œ! (All Systems Operational) âœ¨âœ¨âœ¨")
        print("ì´ì œ ì›¹ì‚¬ì´íŠ¸ì— ì ‘ì†í•˜ì—¬ í•™ë²ˆì„ ì…ë ¥í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        print("="*50 + "\n")

    def _check_and_download_files(self):
        """í•„ìš”í•œ ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ Dropboxì—ì„œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
        files_to_check = [
            {
                "path": os.path.join(self.MODEL_DIR, "TermRecTransformer.pt"),
                "url": "https://www.dropbox.com/scl/fi/jv9ir3ekt0z0m9917u7vr/TermRecTransformer.pt?rlkey=4vatwhzykefbhv68454iuxo4m&dl=1",
                "name": "TermRecTransformer.pt"
            },
            {
                "path": os.path.join(self.EMBEDDING_DIR, "keyword_initial_embeddings.npy"),
                "url": "https://www.dropbox.com/scl/fi/ujlox6xk5v6bsysluqxjy/keyword_initial_embeddings.npy?rlkey=rwfpec4j9we3tt0f3qdg1yya7&dl=1",
                "name": "keyword_initial_embeddings.npy"
            },
            {
                "path": os.path.join(self.DATA_DIR, "df_student_grades_all.pkl"),
                "url": "https://www.dropbox.com/scl/fi/co3msjmaqwygi3x68ktx7/df_student_grades_all.pkl?rlkey=fnje3zi0a5xrerpf245bo1j6c&dl=1",
                "name": "df_student_grades_all.pkl"
            }
        ]

        print("ğŸ“‚ íŒŒì¼ ë¬´ê²°ì„± ë° ë‹¤ìš´ë¡œë“œ í™•ì¸ ì‹œì‘...")
        for file_info in files_to_check:
            if not os.path.exists(file_info["path"]):
                print(f"  âš ï¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {file_info['name']}")
                print(f"  ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {file_info['url']}")
                self._download_file(file_info["url"], file_info["path"])
                print(f"  âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {file_info['name']}")
            else:
                print(f"  âœ… íŒŒì¼ ì¡´ì¬ í™•ì¸: {file_info['name']}")

    def _download_file(self, url, dest_path):
        """URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤."""
        response = requests.get(url, stream=True)
        response.raise_for_status()
        os.makedirs(os.path.dirname(dest_path), exist_ok=True)
        with open(dest_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)

    def _load_preprocessed_data(self):
        print("  - 1/5: ì „ì²˜ë¦¬ëœ ë°ì´í„° ë¡œë”© ì¤‘...")
        with open(os.path.join(self.DATA_DIR, 'encoders.pkl'), 'rb') as f:
            self.encoders = pickle.load(f)
        self.df_list_new_all = pd.read_pickle(os.path.join(self.DATA_DIR, 'df_list_new_all.pkl'))
        self.df_student_data = pd.read_pickle(os.path.join(self.DATA_DIR, 'df_student_data.pkl'))
        self.df_student_grades_all = pd.read_pickle(os.path.join(self.DATA_DIR, 'df_student_grades_all.pkl'))
        
        # ì‚¬ìš©ì í•„í„°ë§ì— í•„ìš”í•œ 2024ë…„ 1í•™ê¸° ë°ì´í„° ë¡œë“œ
        self.list_sub_24 = pd.read_excel(os.path.join(self.RAW_DATA_DIR, "list_new.xlsx"))
        self.grade_sub_24 = pd.read_excel(os.path.join(self.RAW_DATA_DIR, "grade_new_all.xlsx"))
        self.how_sub_24 = pd.read_excel(os.path.join(self.RAW_DATA_DIR, "how_new_all.xlsx"))
        
        year, semester = 2024, 10
        self.list_sub_24 = self.list_sub_24[(self.list_sub_24['SYY'] == year) & (self.list_sub_24['SMT_DIV_CD'] == semester)]
        self.grade_sub_24 = self.grade_sub_24[(self.grade_sub_24['SYY'] == year) & (self.grade_sub_24['SMT_DIV_CD'] == semester)]
        self.how_sub_24 = self.how_sub_24[(self.how_sub_24['SYY'] == year) & (self.how_sub_24['SMT_DIV_CD'] == semester)]

        def parse_schedule(x):
            if isinstance(x, (list, tuple)): return x
            try: return ast.literal_eval(x) if pd.notna(x) else []
            except (ValueError, SyntaxError): return []
        self.list_sub_24['schedule_pairs'] = self.list_sub_24['schedule_pairs'].apply(parse_schedule)

    def _calculate_model_params(self):
        print("  - 2/5: ëª¨ë¸ íŒŒë¼ë¯¸í„° ê³„ì‚° ì¤‘...")
        # í•˜ì´í¼íŒŒë¼ë¯¸í„°
        self.D_MODEL, self.D_ID, self.D_META, self.D_TERM = 128, 32, 32, 16
        self.NHEAD, self.NLAYERS, self.D_FF, self.DROPOUT = 4, 2, 256, 0.3
        self.MAX_LEN_CAP = 150

        def get_max_encoded_val(df, col):
            v = df[col]
            return int(v[v.notna()].max()) if not v.empty else 0

        # Vocab í¬ê¸° ê³„ì‚°
        self.num_courses = max(get_max_encoded_val(self.df_student_grades_all, 'SUBJTNB_encoded'),
                               get_max_encoded_val(self.df_list_new_all, 'SUBJTNB_encoded')) + 1
        self.num_students = self.df_student_data['ID'].max() + 1
        self.num_terms = int(self.df_student_grades_all['course_completed_year_term'].max()) + 1
        self.num_college = len(self.encoders['le_college'].classes_)
        self.num_major = len(self.encoders['le_major'].classes_)
        self.num_major_detail = len(self.encoders['le_md'].classes_)
        # ... (ì›ë³¸ ì½”ë“œì˜ ëª¨ë“  num_ íŒŒë¼ë¯¸í„° ê³„ì‚°) ...
        self.num_gen_type = get_max_encoded_val(self.df_list_new_all, 'general_type_id') + 1
        self.num_gen_subcat = get_max_encoded_val(self.df_list_new_all, 'general_subcategory_id') + 1
        self.num_gen_term = get_max_encoded_val(self.df_list_new_all, 'general_term_id') + 1
        self.num_subject_div = get_max_encoded_val(self.df_list_new_all, 'subject_div_id') + 1
        self.num_subj_cat = get_max_encoded_val(self.df_list_new_all, 'subject_category_id') + 1
        self.num_student_state = get_max_encoded_val(self.df_student_data, 'student_state_id') + 1
        self.num_su_yn = get_max_encoded_val(self.df_student_grades_all, 'su_id') + 1
        self.num_resit_yn = get_max_encoded_val(self.df_student_grades_all, 'retake_id') + 1
        self.num_transfer_type = get_max_encoded_val(self.df_student_data, 'transfer_type_id') + 1
        self.num_second_major = get_max_encoded_val(self.df_student_data, '2ì „ê³µ_id') + 1
        self.num_third_major = get_max_encoded_val(self.df_student_data, '3ì „ê³µ_id') + 1
        self.num_minor_major = get_max_encoded_val(self.df_student_data, 'ë¶€ì „ê³µ_id') + 1
        self.num_second_minor_major = get_max_encoded_val(self.df_student_data, '2ë¶€ì „ê³µ_id') + 1
        self.num_micro_major = get_max_encoded_val(self.df_student_data, 'ë§ˆì´í¬ë¡œì „ê³µ_id') + 1
        self.num_entrance_major_dept = get_max_encoded_val(self.df_student_data, 'ì…ì‹œí•™ê³¼_id') + 1
        self.num_grad_major_dept = get_max_encoded_val(self.df_student_data, 'ì¡¸ì—…í•™ê³¼_id') + 1

    def _load_model(self):
        print("  - 3/5: ëª¨ë¸ êµ¬ì¡° ì •ì˜ ë° ê°€ì¤‘ì¹˜ ë¡œë”© ì¤‘...")
        kw_init = np.load(os.path.join(self.EMBEDDING_DIR, "keyword_initial_embeddings.npy"))
        theme_init = np.load(os.path.join(self.EMBEDDING_DIR, "theme_initial_embeddings.npy"))
        self.dim_kw_precomputed = kw_init.shape[1]
        self.dim_theme_precomputed = theme_init.shape[1]
        kw_tensor = torch.from_numpy(kw_init).float()
        theme_tensor = torch.from_numpy(theme_init).float()
        
        num_hist_cont_feats = 2

        shared_emb = SharedEmbeddings(
            d_id=self.D_ID, d_term=self.D_TERM, d_meta=self.D_META,
            num_students=self.num_students, num_courses=self.num_courses, num_terms=self.num_terms,
            num_college=self.num_college, num_major=self.num_major, num_major_detail=self.num_major_detail,
            num_gen_type=self.num_gen_type, num_gen_subcat=self.num_gen_subcat, num_gen_term=self.num_gen_term,
            num_subject_div=self.num_subject_div, num_subj_cat=self.num_subj_cat, num_su_yn=self.num_su_yn,
            num_resit_yn=self.num_resit_yn, num_student_state=self.num_student_state, num_second_major=self.num_second_major,
            num_third_major=self.num_third_major, num_minor_major=self.num_minor_major,
            num_second_minor_major=self.num_second_minor_major, num_micro_major=self.num_micro_major,
            num_entrance_major_dept=self.num_entrance_major_dept, num_grad_major_dept=self.num_grad_major_dept,
            num_transfer_type=self.num_transfer_type, dim_kw_precomputed=self.dim_kw_precomputed,
            dim_theme_precomputed=self.dim_theme_precomputed,
            initial_keyword_embeddings_tensor=kw_tensor,
            initial_theme_embeddings_tensor=theme_tensor,
            num_history_cont_feats=2 # 'course_completed_year_term', 'student_grade_score'
        )

        self.model = TermRecTransformer(
            shared_emb=shared_emb, 
            num_courses=self.num_courses,
            dim_kw_precomputed=self.dim_kw_precomputed,
            dim_theme_precomputed=self.dim_theme_precomputed,
            num_history_cont_feats=num_hist_cont_feats,
            d_model=self.D_MODEL,   
            nhead=self.NHEAD,        
            d_ff=self.D_FF,           
            nlayers=self.NLAYERS,      
            dropout=self.DROPOUT,      
            d_id=self.D_ID,            
            d_meta=self.D_META,        
            d_term=self.D_TERM,        
            use_positional=True
        )
        
        best_model_path = os.path.join(self.MODEL_DIR, "TermRecTransformer.pt")
        self.model.load_state_dict(torch.load(best_model_path, map_location=self.DEVICE))
        self.model.to(self.DEVICE)
        self.model.eval()


    def _prepare_prediction_assets(self):
            print("  - 4/5: ì¶”ë¡ ìš© ì—ì…‹ ì¤€ë¹„ ì¤‘...")

            # [ê¸°ì¡´ ë¡œì§ í†µí•©]
            # ì „ì²´ í•™ìƒì— ëŒ€í•œ ì´ë ¥ ìƒ˜í”Œ ìƒì„±
            self.all_samples = build_samples_full_history(self.df_student_grades_all)
            self.all_samples_last = filter_last_per_student(self.all_samples)
            
            # [ìˆ˜ì •] í•™ìƒ IDë¡œ ìƒ˜í”Œì„ ë°”ë¡œ ì°¾ê¸° ìœ„í•´ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  ë”•ì…”ë„ˆë¦¬ë¡œ ìºì‹œ
            self.user_sample_info = {s['student_id']: (i, s) for i, s in enumerate(self.all_samples_last)}

            # ê°ì¢… ë³€í™˜ ë§µ(map) ìƒì„± ë° ì €ì¥
            self.encoded2subjtnb = {v: k for k, v in self.encoders['subjt_map'].items() if pd.notna(k) and pd.notna(v)}
            self.encoded2category = (
                self.df_list_new_all[['SUBJTNB_encoded', 'subject_category']]
                .drop_duplicates('SUBJTNB_encoded')
                .set_index('SUBJTNB_encoded')['subject_category']
                .to_dict()
            )
            self.encoded2div = (
                self.df_list_new_all[['SUBJTNB_encoded', 'subject_div']]
                .drop_duplicates('SUBJTNB_encoded')
                .set_index('SUBJTNB_encoded')['subject_div']
                .to_dict()
            )
            self.subjtnb2encoded = {v: k for k, v in self.encoded2subjtnb.items()}
            
            # 2024ë…„ 1í•™ê¸° ê°œì„¤ ê³¼ëª© ID ì§‘í•© ìƒì„±
            subjt_map = self.encoders['subjt_map']
            self.list_sub_24['SUBJTNB_encoded'] = self.list_sub_24['SUBJTNB'].map(subjt_map)
            self.offered_ids = set(self.list_sub_24['SUBJTNB_encoded'].dropna().astype(int).tolist())

            # Collator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
            max_len = min(max((len(s['hist_courses']) for s in self.all_samples), default=0), self.MAX_LEN_CAP)
            self.df_student_data_idx = self.df_student_data.set_index('ID')
            
            # course_meta_map ìƒì„±
            self.course_meta_map = {}
            for _, r in self.df_list_new_all.iterrows():
                cid = safe_int0(r['SUBJTNB_encoded'])
                self.course_meta_map[cid] = {
                    'college': safe_int0(r['college_id']), 'major': safe_int0(r['major_name_id']),
                    'major_detail': safe_int0(r['major_detail_id']), 'gen_type': safe_int0(r['general_type_id']),
                    'gen_subcat': safe_int0(r['general_subcategory_id']), 'gen_term': safe_int0(r['general_term_id']),
                    'subject_div': safe_int0(r['subject_div_id']), 'subject_category': safe_int0(r['subject_category_id']),
                    'difficulty': safe_float0(r['ë‚œì´ë„_num']), 'evaluation': safe_float0(r['ê³¼ëª©í‰ì '])
                }
            
            # history_item_meta_map ìƒì„±
            self.history_item_meta_map = {}
            hist_df = self.df_student_grades_all[['ID', 'SUBJTNB_encoded', 'course_completed_year_term', 'su_id', 'retake_id', 'student_grade_score']]
            for _, r in hist_df.iterrows():
                key = (int(r['ID']), safe_int0(r['SUBJTNB_encoded']), int(r['course_completed_year_term']))
                self.history_item_meta_map[key] = {
                    'su_yn': safe_int0(r['su_id']), 'resit_yn': safe_int0(r['retake_id']),
                    'hist_cont_feats': np.array([safe_float0(r['course_completed_year_term']), safe_float0(r['student_grade_score'])], dtype=np.float32)
                }
            
            self.collate = Collator(
                C=self.num_courses, max_len=max_len, num_history_cont_feats=2,
                history_item_meta_map=self.history_item_meta_map, 
                course_meta_map=self.course_meta_map,
                df_student_data_idx=self.df_student_data_idx
            )
            print("  - 5/5: ì„œë¹„ìŠ¤ ì¤€ë¹„ ì™„ë£Œ.")

    def get_all_predictions_for_student(self, student_id: int):
        """
        [ë¶„ì„ìš©] í•™ìƒ IDë¥¼ ë°›ì•„ ëª¨ë“  ê°œì„¤ ê³¼ëª©ì— ëŒ€í•œ ì›ë³¸ ì˜ˆì¸¡ ì ìˆ˜ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        (ì¤‘ë³µ ë¶„ë°˜ í¬í•¨)
        """
        # 1. í•™ìƒì˜ ë§ˆì§€ë§‰ í•™ê¸° ìƒ˜í”Œ ì°¾ê¸° (self.user_sample_infoëŠ” dict)
        if student_id not in self.user_sample_info:
            print(f"\\nâš ï¸ ID {student_id}ì— í•´ë‹¹í•˜ëŠ” í•™ìƒ ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        _ , sample = self.user_sample_info[student_id]
        predicted_term = sample['target_term'] # â˜…â˜…â˜… ìˆ˜ì •ëœ ë¶€ë¶„ â˜…â˜…â˜…

        # 2. ëª¨ë¸ ì…ë ¥ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„ (self.collate ì‚¬ìš©)
        (hist_ids, hist_terms, mask, stu_ids, _, _,
         course_meta, stu_meta) = self.collate([sample])

        # 3. ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ì ìˆ˜(logits) ê³„ì‚° (self.model, self.DEVICE ì‚¬ìš©)
        self.model.eval()
        with torch.no_grad():
            hist_ids = hist_ids.to(self.DEVICE)
            hist_terms = hist_terms.to(self.DEVICE)
            mask = mask.to(self.DEVICE)
            stu_ids = stu_ids.to(self.DEVICE)
            course_meta = {k: v.to(self.DEVICE) for k, v in course_meta.items()}
            stu_meta = {k: v.to(self.DEVICE) for k, v in stu_meta.items()}

            logits = self.model(hist_ids, hist_terms, mask, stu_ids,
                                course_meta=course_meta, stu_meta=stu_meta)
            
            probs = torch.sigmoid(logits)[0].cpu().numpy()

        # 4. ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameì— ë§¤í•‘ (self.list_sub_24 ì‚¬ìš©)
        predictions_df = self.list_sub_24.copy()
        valid_courses = predictions_df.dropna(subset=['SUBJTNB_encoded']).copy()
        valid_courses['SUBJTNB_encoded'] = valid_courses['SUBJTNB_encoded'].astype(int)
        
        valid_courses['pred_score'] = valid_courses['SUBJTNB_encoded'].apply(
            lambda x: probs[x] if x < len(probs) else 0.0
        )

        sorted_df = valid_courses.sort_values(by='pred_score', ascending=False).reset_index(drop=True)
        return sorted_df, predicted_term 

    def predict_top_k(self, student_id: int):
        """
        í•™ìƒ IDë¥¼ ë°›ì•„ ëª¨ë¸ì„ í†µí•´ Top 80 ê³¼ëª©ì„ ì¶”ì²œí•©ë‹ˆë‹¤.
        get_all_predictions_for_studentë¥¼ í˜¸ì¶œí•˜ì—¬ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        # 1. í—¬í¼ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì˜ˆì¸¡ ê²°ê³¼ì™€ í•™ê¸° ì •ë³´ ë°›ê¸°
        prediction_result = self.get_all_predictions_for_student(student_id)

        if prediction_result is None:
            return None # í•™ìƒ ì •ë³´ê°€ ì—†ëŠ” ê²½ìš° Noneì„ ê·¸ëŒ€ë¡œ ë°˜í™˜

        sorted_predictions_df, predicted_term = prediction_result        

        # 2. ì¤‘ë³µ ê³¼ëª© ì œê±° (ê³¼ëª© ì½”ë“œ ê¸°ì¤€)
        unique_predictions_df = sorted_predictions_df.drop_duplicates(subset=['SUBJTNB_encoded'])

        # 3. Top N ê²°ì • ë° ì¶”ì¶œ
        N = 80
        top_n_df = unique_predictions_df.head(N)
        
        # ì‹¤ì œ ì¶”ì²œëœ ê³¼ëª© ìˆ˜ë¡œ N ì—…ë°ì´íŠ¸
        N = len(top_n_df)

        if N == 0:
            print(f"âš ï¸ ì„œë¹„ìŠ¤: í•™ìƒ ID {student_id}ì—ê²Œ ì¶”ì²œí•  ê³¼ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            return {
                "uid": student_id,
                "predicted_term": predicted_term,
                "N": 0, "topN_idx": [], "topN_subj": [], "topN_vals": []
            }

        # 4. ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜
        topN_idx_list = top_n_df['SUBJTNB_encoded'].tolist()
        topN_subj_list = top_n_df['SUBJTNB'].tolist()
        topN_vals_list = top_n_df['pred_score'].tolist()

        # 5. ìµœì¢… ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ êµ¬ì„± ë° ë°˜í™˜ (ê¸°ì¡´ í˜•ì‹ê³¼ ë™ì¼)
        result = {
            "uid": student_id,
            "predicted_term": predicted_term,
            "N": N,
            "topN_idx": topN_idx_list,
            "topN_subj": topN_subj_list,
            "topN_vals": topN_vals_list,
        }
        
        return result

    # [ì‹ ê·œ ì¶”ê°€] í•™ìƒ ì •ë³´ ë° ì „ì²´ ìˆ˜ê°• ì´ë ¥ì„ ê°€ì ¸ì˜¤ëŠ” ë©”ì„œë“œ
    def get_student_history(self, student_id: int):
        """í•™ìƒì˜ ê¸°ë³¸ ì •ë³´ì™€ ì „ì²´ í•™ê¸° ìˆ˜ê°• ì´ë ¥ì„ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        student_info_df = self.df_student_data[self.df_student_data['ID'] == student_id]
        if student_info_df.empty:
            return None

        # 1. í•™ìƒ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        info = student_info_df.iloc[0].to_dict()

        # 2. ì „ì²´ ìˆ˜ê°• ì´ë ¥ ì¶”ì¶œ (ìˆ«ì í•™ê¸° ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        student_courses_df = self.df_student_grades_all[self.df_student_grades_all['ID'] == student_id]
        
        if student_courses_df.empty:
            courses_by_term = {}
        else:
            # ìˆ«ì í•™ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ ë° ê·¸ë£¹í™”
            sorted_courses_df = student_courses_df.sort_values(by='course_completed_year_term')
            courses_by_term = sorted_courses_df.groupby('course_completed_year_term')['SUBJTNB'].apply(list).to_dict()
        
        # í…œí”Œë¦¿ì—ì„œ ìˆœì„œëŒ€ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•´ (í•™ê¸°, ê³¼ëª©ë¦¬ìŠ¤íŠ¸) íŠœí”Œì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        sorted_history = sorted(courses_by_term.items())

        return {
            'info': info,
            'history': sorted_history
        }
    
    # [ìˆ˜ì •] 1ë‹¨ê³„: ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ "ëŒ€í‘œ ë¶„ë°˜" DataFrameìœ¼ë¡œ ë°˜í™˜
    def predict_top_k_df(self, student_id: int):

        pred_result = self.predict_top_k(student_id)
        if not pred_result or not pred_result.get('topN_subj'):
            return pd.DataFrame()

        top_subjects = pd.DataFrame({
            'SUBJTNB': pred_result['topN_subj'],
            'pred_score': pred_result['topN_vals']
        })
        
        result_df = pd.merge(top_subjects, self.list_sub_24, on='SUBJTNB', how='inner')

        try:
            result_df['CORSE_DVCLS_NO_NUM'] = pd.to_numeric(result_df['CORSE_DVCLS_NO'])
            result_df = result_df.sort_values(['SUBJTNB', 'CORSE_DVCLS_NO_NUM'])
        except Exception:
            pass
            
        unique_result_df = result_df.drop_duplicates(subset='SUBJTNB', keep='first')
        return unique_result_df.sort_values('pred_score', ascending=False).reset_index(drop=True)

    def _normalize_choice_set(self, val, valid_universe=None, to_str=True):

        if val is None:
            return set()
        if isinstance(val, (list, tuple, set)):
            items = val
        else:
            items = [val]

        out = set()
        for x in items:
            try:
                s = str(x).strip() if to_str else x
            except Exception:
                continue
            if valid_universe is not None and s not in valid_universe:
                continue
            out.add(s)
        return out

    def _normalize_subject_category(self, val):

        valid = {'ì „ê³µ', 'êµì–‘', 'ê¸°íƒ€'}
        if val is None:
            return set()
        if isinstance(val, str):
            s = val.strip()
            return {s} if s in valid else set()
        if isinstance(val, (list, tuple, set)):
            return {str(x).strip() for x in val if str(x).strip() in valid}
        return set()

    def _safe_parse_pairs(self, pairs):

        if isinstance(pairs, (list, tuple)):
            out = []
            for p in pairs:
                try:
                    d, t = p
                    t = int(t)
                    out.append((str(d), t))
                except Exception:
                    return []
            return out
        if isinstance(pairs, str):
            try:
                obj = ast.literal_eval(pairs)
                return self._safe_parse_pairs(obj)
            except Exception:
                return []
        return []

    def filter_full_catalog(self, filter_criteria: dict):

        list_df = self.list_sub_24.copy()
        grade_df = self.grade_sub_24.copy()
        how_df = self.how_sub_24.copy()

        # [ì•ˆì „ì¥ì¹˜] ì£¼ìš” ë¬¸ìì—´ ì»¬ëŸ¼ ì •ë¦¬
        str_cols = [
            'subject_category', 'college_name', 'major_name', 'major_detail',
            'general_type', 'general_subcategory', 'general_term',
            'class_style', 'GRADE_EVL_MTHD_DIV_CD1'
        ]
        for col in str_cols:
            if col in list_df.columns:
                list_df[col] = list_df[col].astype(str).str.strip()

        # --- 1. subject_category ì„ íƒ ì²˜ë¦¬ (ë¬¸ìì—´/ë¦¬ìŠ¤íŠ¸ ëª¨ë‘ ì§€ì›) ---
        raw_selected_category = filter_criteria.get('subject_category')
        categories_all = {'ì „ê³µ', 'êµì–‘', 'ê¸°íƒ€'}
        chosen = self._normalize_subject_category(raw_selected_category)
        student_category = chosen if chosen else categories_all

        # --- 2. ë¶„ê¸° ì²˜ë¦¬: ë‹¨ì¼ ì„ íƒ ì‹œì—ë§Œ í•˜ìœ„ í•„í„° í™œì„±í™” ---
        # (ë‹¤ì¤‘ ì„ íƒì´ë©´ ìƒìœ„ ì¹´í…Œê³ ë¦¬ í•„í„°ë§Œ ì ìš©)
        if student_category == {'ì „ê³µ'}:
            df_major_base = list_df[list_df['subject_category'] == 'ì „ê³µ']

            college_universe = set(df_major_base['college_name'].dropna().astype(str).str.strip().unique())
            student_college = self._normalize_choice_set(filter_criteria.get('college_name'), valid_universe=college_universe)
            if not student_college:
                student_college = college_universe
            df_major_tmp = df_major_base[df_major_base['college_name'].isin(student_college)]

            major_universe = set(df_major_tmp['major_name'].dropna().astype(str).str.strip().unique())
            student_major = self._normalize_choice_set(filter_criteria.get('major_name'), valid_universe=major_universe)
            if not student_major:
                student_major = major_universe
            df_major_tmp2 = df_major_tmp[df_major_tmp['major_name'].isin(student_major)]

            detail_universe = set(df_major_tmp2['major_detail'].dropna().astype(str).str.strip().unique())
            student_major_detail = self._normalize_choice_set(filter_criteria.get('major_detail'), valid_universe=detail_universe)
            if not student_major_detail:
                student_major_detail = detail_universe

        elif student_category == {'êµì–‘'}:
            df_general_base = list_df[list_df['subject_category'] == 'êµì–‘']

            gtype_universe = set(df_general_base['general_type'].dropna().astype(str).str.strip().unique())
            student_general_type = self._normalize_choice_set(filter_criteria.get('general_type_gyoyang'), valid_universe=gtype_universe)
            if not student_general_type:
                student_general_type = gtype_universe
            df_gen_tmp = df_general_base[df_general_base['general_type'].isin(student_general_type)]

            gsub_universe = set(df_gen_tmp['general_subcategory'].dropna().astype(str).str.strip().unique())
            student_general_subcat = self._normalize_choice_set(filter_criteria.get('general_subcategory_gyoyang'), valid_universe=gsub_universe)
            if not student_general_subcat:
                student_general_subcat = gsub_universe
            df_gen_tmp2 = df_gen_tmp[df_gen_tmp['general_subcategory'].isin(student_general_subcat)]

            gterm_universe = set(df_gen_tmp2['general_term'].dropna().astype(str).str.strip().unique())
            student_general_term = self._normalize_choice_set(filter_criteria.get('general_term_gyoyang'), valid_universe=gterm_universe)
            if not student_general_term:
                student_general_term = gterm_universe

        elif student_category == {'ê¸°íƒ€'}:
            df_etc_base = list_df[list_df['subject_category'] == 'ê¸°íƒ€']
            etc_universe = set(df_etc_base['general_type'].dropna().astype(str).str.strip().unique())
            student_general_type = self._normalize_choice_set(filter_criteria.get('etc_type'), valid_universe=etc_universe)
            if not student_general_type:
                student_general_type = etc_universe

        # --- 3 & 4. ì„ í˜¸ êµì‹œ ë° ìš”ì¼ ì²˜ë¦¬ ---
        preferred_periods_list = filter_criteria.get('preferred_periods', [])
        preferred_days_list = filter_criteria.get('preferred_days', [])
        preferred_periods = set(map(int, preferred_periods_list)) if preferred_periods_list else set(range(16))
        preferred_days = set(preferred_days_list) if preferred_days_list else {'ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'}

        # --- 5, 6, 7. í•™ì , ìˆ˜ì—…ë°©ì‹, í‰ê°€ê¸°ì¤€ ì²˜ë¦¬ ---
        credit_list = filter_criteria.get('credit', [])
        if credit_list:
            # CDTê°€ float/str í˜¼ì¬ ëŒ€ë¹„
            try:
                preferred_credit = set(map(float, credit_list))
            except Exception:
                preferred_credit = set(credit_list)
        else:
            preferred_credit = set(list_df['CDT'].dropna().unique())

        class_styles_list = filter_criteria.get('class_styles', [])
        preferred_class_styles = set(class_styles_list) if class_styles_list else set(list_df['class_style'].dropna().unique())

        grade_eval_list = filter_criteria.get('grade_evaluation', [])
        grade_evaluation = set(grade_eval_list) if grade_eval_list else set(list_df['GRADE_EVL_MTHD_DIV_CD1'].dropna().unique())

        # --- 8 & 9. ì„±ì  í‰ê°€ ë°©ì‹ & ê°•ì˜ ë°©ì‹ (ë³µìˆ˜ ì„ íƒ) ì²˜ë¦¬ ---
        available_grade_methods = ['ì¤‘ê°„', 'ê¸°ë§', 'í€´ì¦ˆ', 'ê°œì¸ê³¼ì œ', 'íŒ€ê³¼ì œ', 'ë°œí‘œ', 'ì¶œì„', 'ìˆ˜ì—…ì°¸ì—¬ë„', 'ì¶”ê°€1', 'ì¶”ê°€2', 'ì¶”ê°€3', 'ì¶”ê°€4']
        preferred_grade_methods = filter_criteria.get('grade_eval_methods') or available_grade_methods
        unselected_grade = [m for m in available_grade_methods if m not in preferred_grade_methods]

        # í‚¤ ì»¬ëŸ¼ ìë£Œí˜•/ê³µë°± ë°©ì§€
        key_cols = ['SYY', 'SMT_DIV_CD', 'SUBJTNB', 'CORSE_DVCLS_NO']
        for df in (grade_df, how_df, list_df):
            for kc in key_cols:
                if kc in df.columns:
                    df[kc] = df[kc].astype(str).str.strip()

        # grade_df í•„í„°
        grade_use = grade_df.copy()
        for col in available_grade_methods:
            if col in grade_use.columns:
                grade_use[col] = pd.to_numeric(grade_use[col], errors='coerce')
        mask_grade = (
            (grade_use[preferred_grade_methods].fillna(0) >= 1).any(axis=1) &
            (grade_use[unselected_grade].fillna(0) == 0).all(axis=1)
        )
        grade_filtered = grade_use[mask_grade]

        # lecture/how_df í•„í„°
        available_lecture_methods = ['ê°•ì˜', 'ì‹¤ìŠµ', 'ë°œí‘œ', 'í† ë¡ ', 'íŒ€í”„ë¡œì íŠ¸', 'í˜„ì¥ì‹¤ìŠµ', 'ê¸°íƒ€1', 'ê¸°íƒ€2', 'ê¸°íƒ€3']
        preferred_lecture_methods = filter_criteria.get('lecture_methods') or available_lecture_methods
        unselected_lecture = [m for m in available_lecture_methods if m not in preferred_lecture_methods]

        how_use = how_df.copy()
        for col in available_lecture_methods:
            if col in how_use.columns:
                how_use[col] = pd.to_numeric(how_use[col], errors='coerce')
        mask_lecture = (
            (how_use[preferred_lecture_methods].fillna(0) >= 1).any(axis=1) &
            (how_use[unselected_lecture].fillna(0) == 0).all(axis=1)
        )
        how_filtered = how_use[mask_lecture]

        # --- ìµœì¢… í•„í„°ë§(list_df ëŒ€ìƒ) ---
        df_filtered = list_df.copy()
        df_filtered = df_filtered[df_filtered['subject_category'].isin(student_category)]

        if student_category == {'ì „ê³µ'}:
            if filter_criteria.get('college_name'):
                df_filtered = df_filtered[df_filtered['college_name'].isin(student_college)]
            if filter_criteria.get('major_name'):
                df_filtered = df_filtered[df_filtered['major_name'].isin(student_major)]
            if filter_criteria.get('major_detail'):
                df_filtered = df_filtered[df_filtered['major_detail'].isin(student_major_detail)]

        elif student_category == {'êµì–‘'}:
            if filter_criteria.get('general_type_gyoyang'):
                df_filtered = df_filtered[df_filtered['general_type'].isin(student_general_type)]
            if filter_criteria.get('general_subcategory_gyoyang'):
                df_filtered = df_filtered[df_filtered['general_subcategory'].isin(student_general_subcat)]
            if filter_criteria.get('general_term_gyoyang'):
                df_filtered = df_filtered[df_filtered['general_term'].isin(student_general_term)]

        elif student_category == {'ê¸°íƒ€'}:
            if filter_criteria.get('etc_type'):
                df_filtered = df_filtered[df_filtered['general_type'].isin(student_general_type)]

        # ì‹œê°„í‘œ ë§¤ì¹­
        def schedule_match(row_pairs):
            parsed = self._safe_parse_pairs(row_pairs)
            if not parsed:
                # ì‚¬ìš©ìê°€ ìš”ì¼/êµì‹œë¥¼ ì§€ì •í•˜ì§€ ì•Šì•˜ë‹¤ë©´ í†µê³¼, ì§€ì •í–ˆë‹¤ë©´ ì œì™¸
                return not preferred_days_list and not preferred_periods_list
            # ëª¨ë“  (ìš”ì¼,êµì‹œ)ê°€ ì„ í˜¸ ì§‘í•© ë‚´ì— ìˆì–´ì•¼ í†µê³¼
            return all((d in preferred_days and t in preferred_periods) for d, t in parsed)

        if 'schedule_pairs' in df_filtered.columns:
            df_filtered = df_filtered[df_filtered['schedule_pairs'].apply(schedule_match)]

        # ê¸°íƒ€ ë‹¨ì¼ ì„ íƒ í•„í„°
        if 'CDT' in df_filtered.columns:
            # CDTê°€ strì´ë©´ float ë¹„êµê°€ ì•ˆ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³€í™˜ ì‹œë„
            try:
                df_filtered['__CDT_num__'] = pd.to_numeric(df_filtered['CDT'], errors='coerce')
                df_filtered = df_filtered[df_filtered['__CDT_num__'].isin(preferred_credit)]
                df_filtered.drop(columns=['__CDT_num__'], inplace=True)
            except Exception:
                df_filtered = df_filtered[df_filtered['CDT'].isin(preferred_credit)]

        if 'class_style' in df_filtered.columns:
            df_filtered = df_filtered[df_filtered['class_style'].isin(preferred_class_styles)]

        if 'GRADE_EVL_MTHD_DIV_CD1' in df_filtered.columns:
            df_filtered = df_filtered[df_filtered['GRADE_EVL_MTHD_DIV_CD1'].isin(grade_evaluation)]

        # --- [í•µì‹¬] ìµœì¢… ë³‘í•© ë¡œì§ ---
        key_cols = ['SYY', 'SMT_DIV_CD', 'SUBJTNB', 'CORSE_DVCLS_NO']

        l24 = self.list_sub_24.copy()
        g24 = self.grade_sub_24.copy()
        h24 = self.how_sub_24.copy()
        for df0 in (l24, g24, h24):
            for kc in key_cols:
                if kc in df0.columns:
                    df0[kc] = df0[kc].astype(str).str.strip()

        for df1 in (df_filtered, grade_filtered, how_filtered):
            for kc in key_cols:
                if kc in df1.columns:
                    df1[kc] = df1[kc].astype(str).str.strip()

        merged_keys = pd.merge(
            df_filtered[key_cols].drop_duplicates(),
            grade_filtered[key_cols].drop_duplicates(),
            on=key_cols, how='inner'
        )
        merged_keys = pd.merge(
            merged_keys,
            how_filtered[key_cols].drop_duplicates(),
            on=key_cols, how='inner'
        )

        # 2) ê³µí†µ í‚¤ë¡œ ì›ë³¸(ì‚¬ë³¸) í…Œì´ë¸” ì „ì²´ ì •ë³´ ì¬ê²°í•©
        final_df = pd.merge(merged_keys, l24, on=key_cols, how='inner')
        final_df = pd.merge(final_df, g24, on=key_cols, how='inner')
        final_df = pd.merge(final_df, h24, on=key_cols, how='inner')

        final_df = final_df.loc[:, ~final_df.columns.duplicated()].reset_index(drop=True)

        return final_df

    def get_filter_options(self):
        """HTML í…œí”Œë¦¿ì— ì „ë‹¬í•  ëª¨ë“  í•„í„° ì˜µì…˜ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        major_courses = self.list_sub_24[self.list_sub_24['subject_category'] == 'ì „ê³µ'].copy()
        gyoyang_courses = self.list_sub_24[self.list_sub_24['subject_category'] == 'êµì–‘'].copy()
        etc_courses = self.list_sub_24[self.list_sub_24['subject_category'] == 'ê¸°íƒ€']

        etc_type_list = ['ì¼ë°˜ì„ íƒ', 'êµì§ê³¼ì •', 'í‰ìƒêµìœ¡ì‚¬ê³¼ì •']
        general_type_gyoyang_list = [
            gt for gt in gyoyang_courses['general_type'].dropna().unique()
            if gt not in etc_type_list
        ]

        options = {
            'subject_category': sorted(self.list_sub_24['subject_category'].dropna().unique()),
            'credit': sorted(self.list_sub_24['CDT'].dropna().unique()),
            'class_style': sorted(self.list_sub_24['class_style'].dropna().unique()),
            'grade_evaluation': sorted(self.list_sub_24['GRADE_EVL_MTHD_DIV_CD1'].dropna().unique()),
            'general_type_gyoyang': general_type_gyoyang_list,
            'general_term_gyoyang': sorted(gyoyang_courses['general_term'].dropna().unique()),
            'etc_type': etc_type_list,
            'days': ['ì›”', 'í™”', 'ìˆ˜', 'ëª©', 'ê¸ˆ', 'í† ', 'ì¼'],
            'periods': list(range(16)),
            'grade_eval_methods': ['ì¤‘ê°„', 'ê¸°ë§', 'í€´ì¦ˆ', 'ê°œì¸ê³¼ì œ', 'íŒ€ê³¼ì œ', 'ë°œí‘œ', 'ì¶œì„', 'ìˆ˜ì—…ì°¸ì—¬ë„', 'ì¶”ê°€1', 'ì¶”ê°€2', 'ì¶”ê°€3', 'ì¶”ê°€4'],
            'lecture_methods': ['ê°•ì˜', 'ì‹¤ìŠµ', 'ë°œí‘œ', 'í† ë¡ ', 'íŒ€í”„ë¡œì íŠ¸', 'í˜„ì¥ì‹¤ìŠµ', 'ê¸°íƒ€1', 'ê¸°íƒ€2', 'ê¸°íƒ€3']
        }

        # ì „ê³µ ê³„ì¸µ êµ¬ì¡°
        for col in ['college_name', 'major_name', 'major_detail']:
            major_courses[col] = major_courses[col].fillna('N/A')
        major_hierarchy = {}
        unique_colleges = sorted([c for c in major_courses['college_name'].unique() if c != 'N/A'])
        options['college_name'] = unique_colleges
        for college in unique_colleges:
            major_hierarchy[college] = {}
            college_df = major_courses[major_courses['college_name'] == college]
            unique_majors = sorted([m for m in college_df['major_name'].unique() if m != 'N/A'])
            for major in unique_majors:
                major_df = college_df[college_df['major_name'] == major]
                details = sorted([d for d in major_df['major_detail'].unique() if d != 'N/A'])
                major_hierarchy[college][major] = details
        options['major_hierarchy'] = major_hierarchy

        # êµì–‘ ê³„ì¸µ êµ¬ì¡°
        for col in ['general_type', 'general_subcategory']:
            gyoyang_courses[col] = gyoyang_courses[col].fillna('N/A')
        gyoyang_hierarchy = {}
        for g_type in general_type_gyoyang_list:
            type_df = gyoyang_courses[gyoyang_courses['general_type'] == g_type]
            subcategories = sorted([sc for sc in type_df['general_subcategory'].unique() if sc != 'N/A'])
            gyoyang_hierarchy[g_type] = subcategories
        options['gyoyang_hierarchy'] = gyoyang_hierarchy

        return options

    def get_filtered_recommendations(self, student_id: int, filter_criteria: dict):
        """
        ëª¨ë¸ ì¶”ì²œ Top 60 ê³¼ëª©ê³¼ ì‚¬ìš©ì í•„í„°ë§ ê²°ê³¼ì˜ êµì§‘í•©ì„ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤.
        ë¶„ë°˜ì´ ë‹¤ë¥´ë©´ ë‹¤ë¥¸ ê³¼ëª©ìœ¼ë¡œ ì·¨ê¸‰í•©ë‹ˆë‹¤.
        """
        # 1) ëª¨ë¸ ì¶”ì²œ ê²°ê³¼
        pred_result = self.predict_top_k(student_id)
        if not pred_result or not pred_result.get('topN_subj'):
            return pd.DataFrame()

        top_subjects_map = dict(zip(pred_result['topN_subj'], pred_result['topN_vals']))

        # 2) ì‚¬ìš©ì í•„í„° ê²°ê³¼
        custom_filtered_df = self.filter_full_catalog(filter_criteria)

        if custom_filtered_df.empty:
            return pd.DataFrame()

        # ê³µë°± ì œê±°/íƒ€ì… í†µì¼
        custom_filtered_df['SUBJTNB'] = custom_filtered_df['SUBJTNB'].astype(str).str.strip()
        top_subjects_map_cleaned = {str(k).strip(): v for k, v in top_subjects_map.items()}

        # 3) êµì§‘í•©
        intersection_df = custom_filtered_df[custom_filtered_df['SUBJTNB'].isin(top_subjects_map_cleaned.keys())].copy()
        if intersection_df.empty:
            return pd.DataFrame()

        # 4) ì ìˆ˜ ë¶€ì—¬ ë° ì •ë ¬
        intersection_df['pred_score'] = intersection_df['SUBJTNB'].map(top_subjects_map_cleaned)
        cols_front = [
            'SYY', 'SMT_DIV_CD', 'CAMPS_DIV_NM', 'seasonal_semester', 'subject_category',
            'college_name', 'major_name', 'major_detail', 'general_type', 'general_subcategory',
            'general_term', 'CDT', 'SUBJTNB', 'SUBJTNB_ENG', 'CORSE_DVCLS_NO', 'SUBJT_NM',
            'schedule_pairs', 'subject_div', 'L_ID', 'GRADE_EVL_MTHD_DIV_CD1', 'class_style',
            'ë‚œì´ë„', 'keywords', 'ê³¼ëª©í‰ì ', 'theme1', 'theme2'
        ]
        cols_middle_grade = ['ì¤‘ê°„','ê¸°ë§','í€´ì¦ˆ','ê°œì¸ê³¼ì œ','íŒ€ê³¼ì œ','ë°œí‘œ','ì¶œì„','ìˆ˜ì—…ì°¸ì—¬ë„','ì¶”ê°€1','ì¶”ê°€2','ì¶”ê°€3','ì¶”ê°€4']
        cols_middle_how = ['ê°•ì˜','ì‹¤ìŠµ','í† ë¡ ','íŒ€í”„ë¡œì íŠ¸','í˜„ì¥ì‹¤ìŠµ','ê¸°íƒ€1','ê¸°íƒ€2','ê¸°íƒ€3']
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ê³¨ë¼ ì¬ì •ë ¬
        ordered = [c for c in cols_front + cols_middle_grade + cols_middle_how + ['pred_score'] if c in intersection_df.columns]
        intersection_df = intersection_df[ordered]

        return intersection_df.sort_values('pred_score', ascending=False).reset_index(drop=True)

# --- ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
recommendation_service = RecommendationService()
